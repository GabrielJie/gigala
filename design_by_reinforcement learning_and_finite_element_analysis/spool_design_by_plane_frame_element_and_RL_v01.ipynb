{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "import time\n",
    "# import subprocess\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_coord(action, position, g_coord, dx=0.1, change_nodes=list(range(1,9))):\n",
    "        \n",
    "    if action==0:\n",
    "        g_coord[int(2*change_nodes[position])]+=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]+=dx\n",
    "    elif action==1:\n",
    "        g_coord[int(2*change_nodes[position])]+=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]-=dx\n",
    "    if action==2:\n",
    "        g_coord[int(2*change_nodes[position])]-=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]+=dx\n",
    "    elif action==3:\n",
    "        g_coord[int(2*change_nodes[position])]-=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]-=dx    \n",
    "    elif action==4:\n",
    "        g_coord[int(2*change_nodes[position])+1]-=0\n",
    "             \n",
    "    return g_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function must be tailored to different FE models\n",
    "def observe(position, coord, displ):    \n",
    "    return position, coord[0], coord[1],coord[2], coord[3], coord[4], coord[5],coord[6], \\\n",
    "coord[7], coord[8], coord[9],coord[10], coord[11], coord[12], coord[13],coord[14], coord[15],\\\n",
    "coord[16], coord[17],coord[18], coord[19], np.max(abs(displ))\n",
    "\n",
    "\n",
    "#np.sum(abs(displ))\n",
    "\n",
    "#displ[2]\n",
    "\n",
    "# displ[0],displ[1],displ[2],displ[3],displ[4],\\\n",
    "# displ[5],displ[6],displ[7],displ[8],displ[9],displ[10],displ[11],displ[12],displ[13],\\\n",
    "# displ[14],displ[15],displ[16],displ[17],displ[18],displ[19],displ[20],displ[21],\\\n",
    "# displ[22],displ[23],displ[24],displ[25],displ[26],displ[27],displ[28],displ[29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Element Model of the Plane Truss structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameElementLength(x1,y1,x2,y2):\n",
    "    return math.sqrt((x2-x1)*(x2-x1) + (y2-y1)*(y2-y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameElementStiffness(E,A,I,L,theta):\n",
    "    pi=3.14159265   \n",
    "    x = theta*pi/180\n",
    "    C = math.cos(x)\n",
    "    S = math.sin(x)\n",
    "    w1 = A*C*C + 12*I*S*S/(L*L)\n",
    "    w2 = A*S*S + 12*I*C*C/(L*L)\n",
    "    w3 = (A-12*I/(L*L))*C*S\n",
    "    w4 = 6*I*S/L\n",
    "    w5 = 6*I*C/L\n",
    "    \n",
    "    return E/L*np.array([[w1, w3, -w4, -w1, -w3, -w4],[ w3, w2, w5, -w3, -w2, w5],\n",
    "                        [-w4, w5, 4*I, w4, -w5, 2*I],[ -w1, -w3, w4, w1, w3, w4],\n",
    "                        [-w3, -w2, -w5, w3, w2, -w5], [-w4, w5, 2*I, w4, -w5, 4*I]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameAssemble(K,k,i,j):\n",
    "    K[3*i,3*i] = K[3*i,3*i] + k[0,0]\n",
    "    K[3*i,3*i+1] = K[3*i,3*i+1] + k[0,1]    \n",
    "    K[3*i,3*i+2] = K[3*i,3*i+2] + k[0,2]\n",
    "    K[3*i,3*j] = K[3*i,3*j] + k[0,3]\n",
    "    K[3*i,3*j+1] = K[3*i,3*j+1] + k[0,4]\n",
    "    K[3*i,3*j+2] = K[3*i,3*j+2] + k[0,5]\n",
    "    K[3*i+1,3*i] = K[3*i+1,3*i] + k[1,0]\n",
    "    K[3*i+1,3*i+1] = K[3*i+1,3*i+1] + k[1,1]\n",
    "    K[3*i+1,3*i+2] = K[3*i+1,3*i+2] + k[1,2]\n",
    "    K[3*i+1,3*j] = K[3*i+1,3*j] + k[1,3]\n",
    "    K[3*i+1,3*j+1] = K[3*i+1,3*j+1] + k[1,4]\n",
    "    K[3*i+1,3*j+2] = K[3*i+1,3*j+2] + k[1,5]\n",
    "    K[3*i+2,3*i] = K[3*i+2,3*i] + k[2,0]\n",
    "    K[3*i+2,3*i+1] = K[3*i+2,3*i+1] + k[2,1]\n",
    "    K[3*i+2,3*i+2] = K[3*i+2,3*i+2] + k[2,2]\n",
    "    K[3*i+2,3*j] = K[3*i+2,3*j] + k[2,3]\n",
    "    K[3*i+2,3*j+1] = K[3*i,3*j+1] + k[2,4]\n",
    "    K[3*i+2,3*j+2] = K[3*i+2,3*j+2] + k[2,5]\n",
    "    K[3*j,3*i] = K[3*j,3*i] + k[3,0]\n",
    "    K[3*j,3*i+1] = K[3*j,3*i+1] + k[3,1]\n",
    "    K[3*j,3*i+2] = K[3*j,3*i+2] + k[3,2]\n",
    "    K[3*j,3*j] = K[3*j,3*j] + k[3,3]\n",
    "    K[3*j,3*j+1] = K[3*j,3*j+1] + k[3,4]\n",
    "    K[3*j,3*j+2] = K[3*j,3*j+2] + k[3,5]   \n",
    "    K[3*j+1,3*i] = K[3*j+1,3*i] + k[4,0]\n",
    "    K[3*j+1,3*i+1] = K[3*j+1,3*i+1] + k[4,1]\n",
    "    K[3*j+1,3*i+2] = K[3*j+1,3*i+2] + k[4,2]\n",
    "    K[3*j+1,3*j] = K[3*j+1,3*j] + k[4,3]\n",
    "    K[3*j+1,3*j+1] = K[3*j+1,3*j+1] + k[4,4]\n",
    "    K[3*j+1,3*j+2] = K[3*j+1,3*j+2] + k[4,5]\n",
    "    K[3*j+2,3*i] = K[3*j+2,3*i] + k[5,0]\n",
    "    K[3*j+2,3*i+1] = K[3*j+2,3*i+1] + k[5,1]\n",
    "    K[3*j+2,3*i+2] = K[3*j+2,3*i+2] + k[5,2]\n",
    "    K[3*j+2,3*j] = K[3*j+2,3*j] + k[5,3]\n",
    "    K[3*j+2,3*j+1] = K[3*j+2,3*j+1] + k[5,4]\n",
    "    K[3*j+2,3*j+2] = K[3*j+2,3*j+2] + k[5,5]\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FEA_u(coord, elcon, bc_u_elim, f_after_u_elim, I=5e-5, A=1e-4, E=210e6):\n",
    "    K=np.zeros(shape=(3*np.max(elcon)+3,3*np.max(elcon)+3))\n",
    "    pi=3.14159265\n",
    "    for el in elcon:\n",
    "        L=PlaneFrameElementLength(coord[el[0]][0],coord[el[0]][1],coord[el[1]][0],coord[el[1]][1])\n",
    "        theta=math.atan((coord[el[1]][1]-coord[el[0]][1])/(coord[el[1]][0]-coord[el[0]][0]+1e-13))*180/pi\n",
    "        k=PlaneFrameElementStiffness(E,A,I,L,theta)\n",
    "        K=PlaneFrameAssemble(K,k,el[0],el[1])\n",
    "    K=np.delete(K,bc_u_elim,0)\n",
    "    K=np.delete(K,bc_u_elim,1)\n",
    "    \n",
    "\n",
    "    d=np.dot(np.linalg.inv(K),f_after_u_elim)\n",
    "    ans=np.zeros(shape=(3*len(coord)))\n",
    "\n",
    "    j=0\n",
    "    for i in range(len(ans)):\n",
    "        if i not in bc_u_elim:\n",
    "            ans[i]=d[j]\n",
    "            j+=1\n",
    "            if j>len(d)-1:\n",
    "                break\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Policy - Policy Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details of model can be found in the book:\n",
    "# Hands-On Machine Learning with Scikit-Learn & TensorFlow. Aurйlien Gйron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the NN architecture must be tailored to different FE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-11-d7eeea61176c>:16: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 22 \n",
    "n_hidden = 70 \n",
    "n_outputs = 5 \n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Build the neural network\n",
    "X_ = tf.placeholder(tf.float64, shape=[None, n_inputs], name=\"X_\")\n",
    "hidden = fully_connected(X_, n_hidden, activation_fn=tf.nn.elu, weights_initializer=initializer)\n",
    "hidden1 = fully_connected(hidden, n_hidden, activation_fn=tf.nn.elu, weights_initializer=initializer)\n",
    "logits = fully_connected(hidden1, n_outputs, activation_fn=None, weights_initializer=initializer)\n",
    "outputs = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "# Select a random action based on the estimated probabilities\n",
    "action = tf.multinomial(tf.log(outputs), num_samples=1,output_dtype=tf.int32)\n",
    "\n",
    "y=tf.reshape(tf.one_hot(action,depth=5,dtype=tf.float64),[5,1])\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=tf.transpose(logits))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(xentropy)\n",
    "gradients = [grad for grad, variable in grads_and_vars]\n",
    "gradient_placeholders = []\n",
    "grads_and_vars_feed = []\n",
    "for grad, variable in grads_and_vars:\n",
    "    gradient_placeholder = tf.placeholder(tf.float64, shape=grad.get_shape())\n",
    "    gradient_placeholders.append(gradient_placeholder)\n",
    "    grads_and_vars_feed.append((gradient_placeholder, variable))\n",
    "\n",
    "training_op = optimizer.apply_gradients(grads_and_vars_feed)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_rate=0.97):\n",
    "    discounted_rewards = np.empty(len(rewards))\n",
    "    cumulative_rewards = 0\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        cumulative_rewards = rewards[step] + cumulative_rewards * discount_rate\n",
    "        discounted_rewards[step] = cumulative_rewards\n",
    "    return discounted_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_and_normalize_rewards(all_rewards, discount_rate=0.97):\n",
    "    all_discounted_rewards = [discount_rewards(rewards) for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean)/reward_std for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function must be tailored to different FE models\n",
    "\n",
    "def reward_(obs_,obs): \n",
    "#     if np.max(abs(np.array(obs_[22:-1])))>np.max(abs(np.array(obs[22:-1]))): \n",
    "#     if sum(abs(np.array(obs_[22:-1])))>sum(abs(np.array(obs[22:-1]))):\n",
    "#     return sum(abs(np.array(obs_[22:-1]))>abs(np.array(obs[22:-1]))) \n",
    "\n",
    "#     if abs(obs_[-1])>abs(obs[-1]):\n",
    "    if obs_[-1]>obs[-1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training code must be tailored to different FE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 0 epoch 42.31264090538025 sec\n",
      "\n",
      "Time taken for 5 epoch 198.13890194892883 sec\n",
      "\n",
      "Time taken for 10 epoch 350.52830386161804 sec\n",
      "\n",
      "Time taken for 15 epoch 511.6054878234863 sec\n",
      "\n",
      "Time taken for 20 epoch 668.9204878807068 sec\n",
      "\n",
      "Time taken for 25 epoch 790.1450479030609 sec\n",
      "\n",
      "Time taken for 30 epoch 924.8818118572235 sec\n",
      "\n",
      "Time taken for 35 epoch 1044.5332617759705 sec\n",
      "\n",
      "Time taken for 40 epoch 1148.6496307849884 sec\n",
      "\n",
      "Time taken for 45 epoch 1266.6734147071838 sec\n",
      "\n",
      "Time taken for 50 epoch 1396.3372757434845 sec\n",
      "\n",
      "Time taken for 55 epoch 1523.156457901001 sec\n",
      "\n",
      "Time taken for 60 epoch 1655.6883237361908 sec\n",
      "\n",
      "Time taken for 65 epoch 1767.5107808113098 sec\n",
      "\n",
      "Time taken for 70 epoch 1868.1316769123077 sec\n",
      "\n",
      "Time taken for 75 epoch 1968.3633208274841 sec\n",
      "\n",
      "Time taken for 80 epoch 2039.800969839096 sec\n",
      "\n",
      "Time taken for 85 epoch 2110.7327926158905 sec\n",
      "\n",
      "Time taken for 90 epoch 2192.7845458984375 sec\n",
      "\n",
      "Time taken for 95 epoch 2265.571138858795 sec\n",
      "\n",
      "Time taken for 100 epoch 2344.6355748176575 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_iterations =101 #251  # number of training iterations\n",
    "n_max_steps = 500 #1000  # max steps per episode\n",
    "n_games_per_update = 10 # train the policy every 10 episodes\n",
    "save_iterations = 5 # save the model every 10 training iterations\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start=time.time()\n",
    "    init.run() \n",
    "    \n",
    "#     saver.restore(sess, tf.train.latest_checkpoint(\"./policy4/\"))    \n",
    "#     tf.get_default_graph()\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "               \n",
    "        all_rewards = [] # all sequences of raw rewards for each episode\n",
    "        all_gradients = [] # gradients saved at each step of each episode\n",
    "             \n",
    "        for game in range(n_games_per_update):\n",
    "            current_rewards = [] # all raw rewards from the current episode\n",
    "            current_gradients = [] # all gradients from the current episode\n",
    "            \n",
    "            pst=random.randint(0,7)\n",
    "            g_coord = alter_coord(4, pst, np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),\n",
    "                                          dx=0.1, change_nodes=list(range(1,9)))\n",
    "            \n",
    "            \n",
    "            displ = FEA_u(g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_u_elim=[0,1,2],\n",
    "                                                    f_after_u_elim=np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-10,0,0]), \n",
    "                                                    I=5e-5, A=2e-2, E=210e6)\n",
    "            \n",
    "            obs=observe(pst, g_coord,displ)\n",
    "            \n",
    "            \n",
    "            for step in range(n_max_steps):\n",
    "                action_val, gradients_val = sess.run([action, gradients],\n",
    "                                                     feed_dict={X_: np.array(obs).reshape(1,n_inputs)}) \n",
    "                obs_=obs        \n",
    "                g_coord = alter_coord(action_val[0][0], pst, g_coord,\n",
    "                                          dx=0.1, change_nodes=list(range(1,9)))\n",
    "                \n",
    "                pst=random.randint(0,7)\n",
    "                \n",
    "                if PlaneFrameElementLength(g_coord[0],g_coord[1],g_coord[2],g_coord[3])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[2],g_coord[3],g_coord[4],g_coord[5])<0.02:\n",
    "                    break\n",
    "             \n",
    "                if PlaneFrameElementLength(g_coord[4],g_coord[5],g_coord[6],g_coord[7])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[6],g_coord[7],g_coord[8],g_coord[9])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[8],g_coord[9],g_coord[10],g_coord[11])<0.02:\n",
    "                    break\n",
    "            \n",
    "             \n",
    "                if PlaneFrameElementLength(g_coord[10],g_coord[11],g_coord[12],g_coord[13])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[12],g_coord[13],g_coord[14],g_coord[15])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[14],g_coord[15],g_coord[16],g_coord[17])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[16],g_coord[17],g_coord[18],g_coord[19])<0.02:\n",
    "                    break\n",
    "                            \n",
    "                \n",
    "                displ = FEA_u(g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_u_elim=[0,1,2],\n",
    "                                                    f_after_u_elim=np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-10,0,0]), \n",
    "                                                    I=5e-5, A=2e-2, E=210e6)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                obs=observe(pst,g_coord,displ) \n",
    "                \n",
    "                reward=reward_(obs_,obs)\n",
    "                \n",
    "                current_rewards.append(reward)\n",
    "                current_gradients.append(gradients_val)\n",
    "\n",
    "            all_rewards.append(current_rewards)\n",
    "            all_gradients.append(current_gradients)\n",
    "\n",
    "    \n",
    "            \n",
    "        # At this point we have run the policy for 10 episodes, and we are\n",
    "        # ready for a policy update using the algorithm described earlier.\n",
    "        all_rewards = discount_and_normalize_rewards(all_rewards)\n",
    "        \n",
    "        \n",
    "        \n",
    "        feed_dict = {}\n",
    "        for var_index, grad_placeholder in enumerate(gradient_placeholders):\n",
    "            # multiply the gradients by the action scores, and compute the mean\n",
    "            mean_gradients = np.mean([reward * all_gradients[game_index][step][var_index] \n",
    "                                      for game_index, rewards in enumerate(all_rewards)\n",
    "                                      for step, reward in enumerate(rewards)],axis=0)\n",
    "            feed_dict[grad_placeholder] = mean_gradients\n",
    "        \n",
    "        \n",
    "        sess.run(training_op, feed_dict=feed_dict)\n",
    "        \n",
    "        if iteration % save_iterations == 0:\n",
    "#             print(\"Saving {} iteration\".format(iteration))\n",
    "            print('Time taken for {} epoch {} sec\\n'.format(iteration, time.time() - start))\n",
    "            saver.save(sess, \"./policy4/pinjointed4.ckpt\")\n",
    "\n",
    "# end=time.time()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI designing the spool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(coord):\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph('./policy4/pinjointed4.ckpt.meta')\n",
    "        saver.restore(sess, \"./policy4/pinjointed4.ckpt\") \n",
    "\n",
    "        graph = tf.get_default_graph()\n",
    "        outputs = graph.get_tensor_by_name(\"Y_proba:0\") \n",
    "        X_ = graph.get_tensor_by_name(\"X_:0\") \n",
    "                \n",
    "#         pst=random.randint(0,7)\n",
    "        \n",
    "        j=0\n",
    "        pst=j%8\n",
    "        g_coord = alter_coord(4, pst, coord, dx=0.1, change_nodes=list(range(1,9)))\n",
    "            \n",
    "        displ = FEA_u(g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_u_elim=[0,1,2],\n",
    "                                                    f_after_u_elim=np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-10,0,0]), \n",
    "                                                    I=5e-5, A=2e-2, E=210e6)\n",
    "            \n",
    "        obs=observe(pst, g_coord,  displ)       \n",
    "        \n",
    "        print(\"before: \", np.max(abs(displ)))\n",
    "        \n",
    "        for step in range(50):\n",
    "            action_val= sess.run([outputs],feed_dict={X_: np.array(obs).reshape(1,n_inputs)})\n",
    "            \n",
    "            action_val=np.log(action_val)\n",
    "            g_coord = alter_coord( np.argmax(action_val), pst, g_coord, dx=0.1, change_nodes=list(range(1,9)))\n",
    "            \n",
    "            \n",
    "#             print(pst)\n",
    "#             pst=random.randint(0,7)\n",
    "            j+=1\n",
    "            pst=j%8\n",
    "        \n",
    "            if PlaneFrameElementLength(g_coord[0],g_coord[1],g_coord[2],g_coord[3])<0.02:\n",
    "                break\n",
    "            \n",
    "            if PlaneFrameElementLength(g_coord[2],g_coord[3],g_coord[4],g_coord[5])<0.02:\n",
    "                break\n",
    "             \n",
    "            if PlaneFrameElementLength(g_coord[4],g_coord[5],g_coord[6],g_coord[7])<0.02:\n",
    "                break\n",
    "            \n",
    "            if PlaneFrameElementLength(g_coord[6],g_coord[7],g_coord[8],g_coord[9])<0.02:\n",
    "                break\n",
    "            \n",
    "            if PlaneFrameElementLength(g_coord[8],g_coord[9],g_coord[10],g_coord[11])<0.02:\n",
    "                break\n",
    "                \n",
    "            if PlaneFrameElementLength(g_coord[10],g_coord[11],g_coord[12],g_coord[13])<0.02:\n",
    "                break\n",
    "            \n",
    "            if PlaneFrameElementLength(g_coord[12],g_coord[13],g_coord[14],g_coord[15])<0.02:\n",
    "                break\n",
    "            \n",
    "            if PlaneFrameElementLength(g_coord[14],g_coord[15],g_coord[16],g_coord[17])<0.02:\n",
    "                break\n",
    "            \n",
    "            if PlaneFrameElementLength(g_coord[16],g_coord[17],g_coord[18],g_coord[19])<0.02:\n",
    "                break\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            displ = FEA_u(g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_u_elim=[0,1,2],\n",
    "                                                    f_after_u_elim=np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-10,0,0]), \n",
    "                                                    I=5e-5, A=2e-2, E=210e6)\n",
    "            \n",
    "            obs=observe(pst, g_coord, displ)\n",
    "        print(\"after: \", np.max(abs(displ)))\n",
    "#         print(\"after: \", abs(displ[2]))\n",
    "        return obs,g_coord        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./policy4/pinjointed4.ckpt\n",
      "before:  1.3885714292728\n",
      "after:  0.17816316274978494\n"
     ]
    }
   ],
   "source": [
    "obs, g_coord = predict(np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0. ,  2.3, -0.7,  5.3, -0.7,  8.4, -0.6,  8.4,  2.4,  8.4,\n",
       "        5.4,  8.4,  8.4, 11.4,  8.4, 14.4,  8.4, 18. ,  9. ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(coord,color,elcon):\n",
    "    coord=coord.reshape(np.max(elcon)+1,2)\n",
    "    plt.figure(figsize=(13,5))\n",
    "    for item in elcon:\n",
    "        plt.plot([coord[item[0]][0],coord[item[1]][0]],[coord[item[0]][1],coord[item[1]][1]],color=color)\n",
    "       \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(np.array([0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),color=\"green\",elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design by AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(g_coord,color=\"blue\",elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
