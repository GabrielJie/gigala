{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install stable_baselines3==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import A2C, SAC,PPO\n",
    "import torch\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common import results_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_coord(action, position, g_coord, dx=0.1, change_nodes=list(range(1,9))):\n",
    "        \n",
    "    if action==0:\n",
    "        g_coord[int(2*change_nodes[position])]+=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]+=dx\n",
    "    elif action==1:\n",
    "        g_coord[int(2*change_nodes[position])]+=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]-=dx\n",
    "    if action==2:\n",
    "        g_coord[int(2*change_nodes[position])]-=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]+=dx\n",
    "    elif action==3:\n",
    "        g_coord[int(2*change_nodes[position])]-=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]-=dx    \n",
    "    elif action==4:\n",
    "        g_coord[int(2*change_nodes[position])+1]-=0\n",
    "             \n",
    "    return g_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe(position, coord, displ, action):    \n",
    "    return position, coord[0], coord[1],coord[2], coord[3], coord[4], coord[5],coord[6], \\\n",
    "coord[7], coord[8], coord[9],coord[10], coord[11], coord[12], coord[13],coord[14], coord[15],\\\n",
    "coord[16], coord[17],coord[18], coord[19], np.max(abs(displ)),action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(coord,color,elcon):\n",
    "    coord=coord.reshape(np.max(elcon)+1,2)\n",
    "    plt.figure(figsize=(13,5))\n",
    "    for item in elcon:\n",
    "        plt.plot([coord[item[0]][0],coord[item[1]][0]],[coord[item[0]][1],coord[item[1]][1]],color=color)\n",
    "       \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_(obs_,obs): \n",
    "    if obs_[-1]>obs[-1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Element Model of the Plane Frame structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameElementLength(x1,y1,x2,y2):\n",
    "    return math.sqrt((x2-x1)*(x2-x1) + (y2-y1)*(y2-y1))+10e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameElementStiffness(E,A,I,L,theta):\n",
    "    pi=math.pi \n",
    "    x = theta*pi/180\n",
    "    C = math.cos(x)\n",
    "    S = math.sin(x)\n",
    "    w1 = A*C*C + 12*I*S*S/(L*L)\n",
    "    w2 = A*S*S + 12*I*C*C/(L*L)\n",
    "    w3 = (A-12*I/(L*L))*C*S\n",
    "    w4 = 6*I*S/L\n",
    "    w5 = 6*I*C/L\n",
    "    \n",
    "    return E/L*np.array([[w1, w3, -w4, -w1, -w3, -w4],[ w3, w2, w5, -w3, -w2, w5],\n",
    "                        [-w4, w5, 4*I, w4, -w5, 2*I],[ -w1, -w3, w4, w1, w3, w4],\n",
    "                        [-w3, -w2, -w5, w3, w2, -w5], [-w4, w5, 2*I, w4, -w5, 4*I]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameAssemble(K,k,i,j):\n",
    "    K[3*i,3*i] = K[3*i,3*i] + k[0,0]\n",
    "    K[3*i,3*i+1] = K[3*i,3*i+1] + k[0,1]    \n",
    "    K[3*i,3*i+2] = K[3*i,3*i+2] + k[0,2]\n",
    "    K[3*i,3*j] = K[3*i,3*j] + k[0,3]\n",
    "    K[3*i,3*j+1] = K[3*i,3*j+1] + k[0,4]\n",
    "    K[3*i,3*j+2] = K[3*i,3*j+2] + k[0,5]\n",
    "    K[3*i+1,3*i] = K[3*i+1,3*i] + k[1,0]\n",
    "    K[3*i+1,3*i+1] = K[3*i+1,3*i+1] + k[1,1]\n",
    "    K[3*i+1,3*i+2] = K[3*i+1,3*i+2] + k[1,2]\n",
    "    K[3*i+1,3*j] = K[3*i+1,3*j] + k[1,3]\n",
    "    K[3*i+1,3*j+1] = K[3*i+1,3*j+1] + k[1,4]\n",
    "    K[3*i+1,3*j+2] = K[3*i+1,3*j+2] + k[1,5]\n",
    "    K[3*i+2,3*i] = K[3*i+2,3*i] + k[2,0]\n",
    "    K[3*i+2,3*i+1] = K[3*i+2,3*i+1] + k[2,1]\n",
    "    K[3*i+2,3*i+2] = K[3*i+2,3*i+2] + k[2,2]\n",
    "    K[3*i+2,3*j] = K[3*i+2,3*j] + k[2,3]\n",
    "    K[3*i+2,3*j+1] = K[3*i,3*j+1] + k[2,4]\n",
    "    K[3*i+2,3*j+2] = K[3*i+2,3*j+2] + k[2,5]\n",
    "    K[3*j,3*i] = K[3*j,3*i] + k[3,0]\n",
    "    K[3*j,3*i+1] = K[3*j,3*i+1] + k[3,1]\n",
    "    K[3*j,3*i+2] = K[3*j,3*i+2] + k[3,2]\n",
    "    K[3*j,3*j] = K[3*j,3*j] + k[3,3]\n",
    "    K[3*j,3*j+1] = K[3*j,3*j+1] + k[3,4]\n",
    "    K[3*j,3*j+2] = K[3*j,3*j+2] + k[3,5]   \n",
    "    K[3*j+1,3*i] = K[3*j+1,3*i] + k[4,0]\n",
    "    K[3*j+1,3*i+1] = K[3*j+1,3*i+1] + k[4,1]\n",
    "    K[3*j+1,3*i+2] = K[3*j+1,3*i+2] + k[4,2]\n",
    "    K[3*j+1,3*j] = K[3*j+1,3*j] + k[4,3]\n",
    "    K[3*j+1,3*j+1] = K[3*j+1,3*j+1] + k[4,4]\n",
    "    K[3*j+1,3*j+2] = K[3*j+1,3*j+2] + k[4,5]\n",
    "    K[3*j+2,3*i] = K[3*j+2,3*i] + k[5,0]\n",
    "    K[3*j+2,3*i+1] = K[3*j+2,3*i+1] + k[5,1]\n",
    "    K[3*j+2,3*i+2] = K[3*j+2,3*i+2] + k[5,2]\n",
    "    K[3*j+2,3*j] = K[3*j+2,3*j] + k[5,3]\n",
    "    K[3*j+2,3*j+1] = K[3*j+2,3*j+1] + k[5,4]\n",
    "    K[3*j+2,3*j+2] = K[3*j+2,3*j+2] + k[5,5]\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FEA_u(coord, elcon, bc_node, bc_val, global_force, I=5e-5, A=2e-2, E=210e6):\n",
    "    K=np.zeros(shape=(3*np.max(elcon)+3,3*np.max(elcon)+3))\n",
    "    pi=math.pi\n",
    "    for el in elcon:\n",
    "        L=PlaneFrameElementLength(coord[el[0]][0],coord[el[0]][1],coord[el[1]][0],coord[el[1]][1])\n",
    "        theta=math.atan((coord[el[1]][1]-coord[el[0]][1])/(coord[el[1]][0]-coord[el[0]][0]+1e-13))*180/pi\n",
    "        k=PlaneFrameElementStiffness(E,A,I,L,theta)\n",
    "        K=PlaneFrameAssemble(K,k,el[0],el[1])\n",
    "    \n",
    "    \n",
    "    F = np.array(global_force)\n",
    "    \n",
    "    \n",
    "    # https://github.com/CALFEM/calfem-matlab/blob/master/fem/solveq.m\n",
    "    \n",
    "    bc=np.array([bc_node, \n",
    "                bc_val]).T\n",
    "    nd, nd=K.shape\n",
    "    fdof=np.array([i for i in range(nd)]).T\n",
    "    d=np.zeros(shape=(len(fdof),))\n",
    "    Q=np.zeros(shape=(len(fdof),))\n",
    "\n",
    "    pdof=bc[:,0].astype(int)\n",
    "    dp=bc[:,1]\n",
    "    fdof=np.delete(fdof, pdof, 0)\n",
    "    \n",
    "    K[np.isnan(K)] = 0\n",
    "    F[np.isnan(F)] = 0\n",
    "    \n",
    "    s=np.linalg.lstsq(K[fdof,:][:,fdof], (F[fdof].T-np.dot(K[fdof,:][:,pdof],dp.T)).T, rcond=None)[0] \n",
    "    d[pdof]=dp\n",
    "    d[fdof]=s.reshape(-1,)\n",
    "    \n",
    "#     Q=np.dot(K,d).T-F \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 The Plane Frame Element - verification\n",
    "d = FEA_u(np.array([0,0,\n",
    "                    0,3,\n",
    "                    4,3,\n",
    "                    4,0]).reshape(4,2),\n",
    "          elcon=np.array([[0, 1],\n",
    "                      [1, 2],\n",
    "                      [2, 3]]),\n",
    "          bc_node=[0,1,2,9,10,11], \n",
    "          bc_val=[0,0,0,0,0,0], \n",
    "          global_force=[0,0,0,-20,0,0,0,0,12,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DISCRETE_ACTIONS=5\n",
    "DIM=23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrussEnv(gym.Env):\n",
    "    \n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.action_space = spaces.Discrete(N_DISCRETE_ACTIONS)\n",
    "        \n",
    "        self.pst=random.randint(0,7)\n",
    "        self.g_coord = alter_coord(4, self.pst, \n",
    "                                   np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),\n",
    "                                   dx=0.1, \n",
    "                                   change_nodes=list(range(1,9)))\n",
    "            \n",
    "            \n",
    "        self.displ = FEA_u(self.g_coord.reshape(10,2), \n",
    "                           elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                           bc_node=[0,1,2], \n",
    "                           bc_val=[0,0,0], \n",
    "                           global_force=np.array([0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  -10,0,0]))\n",
    "        self.obs=observe(self.pst, self.g_coord, self.displ,0)\n",
    "        self.observation_space = spaces.Box(low=np.array([-np.inf for x in range(DIM)]),\n",
    "                                            high=np.array([np.inf for y in range(DIM)]),\n",
    "                                            shape=(DIM,),\n",
    "                                           dtype=np.float64)\n",
    "        self.needs_reset = True\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        obs_=self.obs        \n",
    "        self.g_coord = alter_coord(action, self.pst, self.g_coord,\n",
    "                                  dx=0.1, change_nodes=list(range(1,9)))\n",
    "\n",
    "        self.pst=random.randint(0,7)\n",
    "        \n",
    "        done =False\n",
    "        if PlaneFrameElementLength(self.g_coord[0],\n",
    "                                   self.g_coord[1],\n",
    "                                   self.g_coord[2],\n",
    "                                   self.g_coord[3])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[2],\n",
    "                                   self.g_coord[3],\n",
    "                                   self.g_coord[4],\n",
    "                                   self.g_coord[5])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[4],\n",
    "                                   self.g_coord[5],\n",
    "                                   self.g_coord[6],\n",
    "                                   self.g_coord[7])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[6],\n",
    "                                   self.g_coord[7],\n",
    "                                   self.g_coord[8],\n",
    "                                   self.g_coord[9])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[8],\n",
    "                                   self.g_coord[9],\n",
    "                                   self.g_coord[10],\n",
    "                                   self.g_coord[11])<0.02:\n",
    "            done=True\n",
    "\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[10],\n",
    "                                   self.g_coord[11],\n",
    "                                   self.g_coord[12],\n",
    "                                   self.g_coord[13])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[12],\n",
    "                                   self.g_coord[13],\n",
    "                                   self.g_coord[14],\n",
    "                                   self.g_coord[15])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[14],\n",
    "                                   self.g_coord[15],\n",
    "                                   self.g_coord[16],\n",
    "                                   self.g_coord[17])<0.02:\n",
    "            done=True\n",
    "\n",
    "        if PlaneFrameElementLength(self.g_coord[16],\n",
    "                                   self.g_coord[17],\n",
    "                                   self.g_coord[18],\n",
    "                                   self.g_coord[19])<0.02:\n",
    "            done=True\n",
    "\n",
    "\n",
    "        self.displ = FEA_u(self.g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                           bc_node=[0,1,2], \n",
    "                                           bc_val=[0,0,0], \n",
    "                                           global_force=np.array([0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  -10,0,0]))\n",
    "\n",
    "        self.obs=observe(self.pst,self.g_coord,self.displ,action) \n",
    "\n",
    "        reward=reward_(obs_, self.obs)\n",
    "        \n",
    "        if self.needs_reset:\n",
    "            raise RuntimeError(\"Tried to step environment that needs reset\")\n",
    "            \n",
    "        if done:\n",
    "            self.needs_reset = True\n",
    "      \n",
    "        return np.array(self.obs), reward, done, dict()\n",
    "\n",
    "    def reset(self):\n",
    "        self.pst=random.randint(0,7)\n",
    "        self.g_coord = alter_coord(4, self.pst, np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),\n",
    "                                          dx=0.1, change_nodes=list(range(1,9)))\n",
    "            \n",
    "            \n",
    "        self.displ = FEA_u(self.g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_node=[0,1,2], \n",
    "                                                    bc_val=[0,0,0], \n",
    "                                                    global_force=np.array([0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  -10,0,0]))\n",
    "        self.obs=observe(self.pst, self.g_coord, self.displ,0)\n",
    "        self.needs_reset = False\n",
    "        return np.array(self.obs)  \n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        draw(self.g_coord,\n",
    "             color=\"blue\",\n",
    "             elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]))\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                    print(\n",
    "                        f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
    "                    )\n",
    "\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"Saving new best model to {self.save_path}.zip\")\n",
    "                    self.model.save(self.save_path)\n",
    "\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log dir\n",
    "log_dir = \"/tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = TrussEnv()\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = Monitor(env, log_dir)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts=1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "# action_noise = NormalActionNoise(mean=np.zeros(N_DISCRETE_ACTIONS), sigma=0.1 * np.ones(N_DISCRETE_ACTIONS))\n",
    "model = PPO(\"MlpPolicy\", env,verbose=0).learn(total_timesteps=ts, callback=callback)\n",
    "end=time.time()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total time taken: {} min'.format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design by AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i<50:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    i+=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(env.displ),max(env.displ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(np.array([0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),\n",
    "     color=\"green\",\n",
    "     elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst=random.randint(0,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_coord = alter_coord(4, pst, np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),\n",
    "                                          dx=0.1, change_nodes=list(range(1,9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis=FEA_u(g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_node=[0,1,2], \n",
    "                                                    bc_val=[0,0,0], \n",
    "                                        global_force=np.array([0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  0,0,0,\n",
    "                                                  -10,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(dis), max(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper from the library\n",
    "results_plotter.plot_results([log_dir], ts, results_plotter.X_TIMESTEPS, \"PPO TrussEnv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
